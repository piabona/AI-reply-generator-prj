{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/swoo-nam/project_final_team1/blob/main/%EC%9D%B4%EC%9A%A9%EB%AF%BC_42000_%EC%A0%9C%EB%A1%9C%EC%83%B7_5%EB%9D%BC%EB%B2%A8%ED%95%99%EC%8A%B5.ipynb","timestamp":1695453654069}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"daed303e51804ac5a7ea438243b12419":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58f0110eb6a84d7fb92b6e89de33540b","IPY_MODEL_e4ca2834e27841aea4793a81bfb0d206","IPY_MODEL_ad67f4d461d346218b8b2df8850a686f"],"layout":"IPY_MODEL_3346964b0b384ad2b4b060eb90510250"}},"58f0110eb6a84d7fb92b6e89de33540b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3025b5b0ab94c389c6569a8969e3d37","placeholder":"​","style":"IPY_MODEL_fa12003cdd504795822f976c9bab635a","value":"Downloading (…)lve/main/config.json: 100%"}},"e4ca2834e27841aea4793a81bfb0d206":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c606a9e6e7584bb3b8f3287743e746c2","max":1066,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ed6adbefcf8405aa965274a1763b3bd","value":1066}},"ad67f4d461d346218b8b2df8850a686f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c483bfbcc64642bf82608ed0db08108b","placeholder":"​","style":"IPY_MODEL_a67f8568404d447d829fefb4dd1f0fa7","value":" 1.07k/1.07k [00:00&lt;00:00, 16.9kB/s]"}},"3346964b0b384ad2b4b060eb90510250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3025b5b0ab94c389c6569a8969e3d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa12003cdd504795822f976c9bab635a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c606a9e6e7584bb3b8f3287743e746c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ed6adbefcf8405aa965274a1763b3bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c483bfbcc64642bf82608ed0db08108b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a67f8568404d447d829fefb4dd1f0fa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05b41e54282640c0a3b760a148ddd1aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c87f56abdc4479e94ee38f6daca5904","IPY_MODEL_bbb890ae0b414af28621ae73faa99b86","IPY_MODEL_d71e1e1822c44dc49bb9576436cf877b"],"layout":"IPY_MODEL_852677599b204e27a5e199294720d06b"}},"9c87f56abdc4479e94ee38f6daca5904":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4552baae85543f2bc0224e7a1f7a422","placeholder":"​","style":"IPY_MODEL_9d37ebe27f3946ccadc2277e4ce4b5cb","value":"Downloading model.safetensors: 100%"}},"bbb890ae0b414af28621ae73faa99b86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3fd5bbefd444335a1a1952784d3a93c","max":557652046,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adc2bab9ccc5474683f2834e639d0443","value":557652046}},"d71e1e1822c44dc49bb9576436cf877b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b391f4c7b8f4358aedc9c3ba8f1e3ac","placeholder":"​","style":"IPY_MODEL_ab1562e739ad4e6fbd14d8dd56e302a5","value":" 558M/558M [00:05&lt;00:00, 82.7MB/s]"}},"852677599b204e27a5e199294720d06b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4552baae85543f2bc0224e7a1f7a422":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d37ebe27f3946ccadc2277e4ce4b5cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3fd5bbefd444335a1a1952784d3a93c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adc2bab9ccc5474683f2834e639d0443":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b391f4c7b8f4358aedc9c3ba8f1e3ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab1562e739ad4e6fbd14d8dd56e302a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xErrH2fiZg3c"},"outputs":[],"source":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","import torch\n","from tqdm.auto import tqdm\n","import random\n","import os\n","from tqdm.notebook import tqdm\n","\n","def reset_seeds(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","DATA_PATH = \"/content/drive/MyDrive/프로젝트/final project/data/\"\n","SEED = 42\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device\n","\n","# df = pd.read_csv(f\"{DATA_PATH}yogiyo_reviews_0905_clean.csv\")\n","# df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"qoAWzqppiT6R","outputId":"7de97672-40c6-457f-95fc-02f55ef0737a","executionInfo":{"status":"ok","timestamp":1695432795992,"user_tz":-540,"elapsed":49887,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UobzFb4yiWRB","outputId":"7f35f712-6d48-4bf4-f4be-b2e368b1a0e5","executionInfo":{"status":"ok","timestamp":1695432819263,"user_tz":-540,"elapsed":23284,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"974j7JLMi8jK","outputId":"a930963b-a1fa-40a8-b124-a2383f77bbd0","executionInfo":{"status":"ok","timestamp":1695432828964,"user_tz":-540,"elapsed":9716,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n","\n","# 모델과 토크나이저 초기화\n","model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name).to('cuda')\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n"],"metadata":{"id":"giCgyHjIploi","colab":{"base_uri":"https://localhost:8080/","height":467,"referenced_widgets":["daed303e51804ac5a7ea438243b12419","58f0110eb6a84d7fb92b6e89de33540b","e4ca2834e27841aea4793a81bfb0d206","ad67f4d461d346218b8b2df8850a686f","3346964b0b384ad2b4b060eb90510250","b3025b5b0ab94c389c6569a8969e3d37","fa12003cdd504795822f976c9bab635a","c606a9e6e7584bb3b8f3287743e746c2","7ed6adbefcf8405aa965274a1763b3bd","c483bfbcc64642bf82608ed0db08108b","a67f8568404d447d829fefb4dd1f0fa7","05b41e54282640c0a3b760a148ddd1aa","9c87f56abdc4479e94ee38f6daca5904","bbb890ae0b414af28621ae73faa99b86","d71e1e1822c44dc49bb9576436cf877b","852677599b204e27a5e199294720d06b","c4552baae85543f2bc0224e7a1f7a422","9d37ebe27f3946ccadc2277e4ce4b5cb","c3fd5bbefd444335a1a1952784d3a93c","adc2bab9ccc5474683f2834e639d0443","5b391f4c7b8f4358aedc9c3ba8f1e3ac","ab1562e739ad4e6fbd14d8dd56e302a5"]},"outputId":"b817a806-23de-42c6-c406-198f5904dda4","executionInfo":{"status":"error","timestamp":1695432861124,"user_tz":-540,"elapsed":32175,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daed303e51804ac5a7ea438243b12419"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05b41e54282640c0a3b760a148ddd1aa"}},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-b4db85ac8e29>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 모델과 토크나이저 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2063\u001b[0m             )\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}]},{"cell_type":"code","source":["result_df = pd.read_csv(f\"{DATA_PATH}train_ft_42000_0922.csv\")"],"metadata":{"id":"y5ITeqBzqV4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df"],"metadata":{"id":"MOP44UYjNIfi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df[\"category\"].unique()"],"metadata":{"id":"WNHb_XvSeOmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df.rename(columns={\n","    'review': 'Review',\n","    'category': 'Label'\n","}, inplace=True)\n","result_df = result_df[[\"Review\", \"Label\"]]"],"metadata":{"id":"lPZjobSSqSTs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df"],"metadata":{"id":"hULtfU_IM91Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df = result_df.dropna().reset_index(drop=True)"],"metadata":{"id":"kjRcQZ5YtWfu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HnjyQBeoSzpa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["re_1000 = result_df[:40000]\n","re_1001 = result_df[40000:42500]"],"metadata":{"id":"PgYJ4zHNqoRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["re_1000"],"metadata":{"id":"i3j5GaPh4PMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install accelerate -U"],"metadata":{"id":"ElQTFUO8igAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(re_1000[\"Label\"])"],"metadata":{"id":"WosCS6t_t2gQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# 레이블을 숫자로 변환하는 딕셔너리\n","label_to_num = {0: '맛', 1: '양', 2: '가격', 3: '배달', 4: '서비스'}\n","\n","def string_to_list(label_str):\n","    if isinstance(label_str, str):\n","        # 작은 따옴표를 제거하고 split\n","        return [label.replace(\"'\", \"\").strip() for label in label_str[1:-1].split(',')]\n","    return label_str\n","\n","# labels_to_onehot 함수 수정\n","def labels_to_onehot(labels, label_to_num):\n","    onehot = [0]*len(label_to_num)\n","    for label in labels:\n","        for key, value in label_to_num.items():\n","            if label == value:\n","                onehot[key] = 1\n","    return onehot\n","\n","# re_1000 데이터에 대한 문자열 레이블을 리스트로 변환\n","re_1000['Label_List'] = re_1000['Label'].apply(string_to_list)\n","\n","# re_1000 데이터에 대한 리스트 형태의 레이블을 one-hot encoding으로 변환\n","re_1000['OneHot_Labels'] = re_1000['Label_List'].apply(lambda x: labels_to_onehot(x, label_to_num))\n","\n","# re_1001 데이터에 대한 문자열 레이블을 리스트로 변환\n","re_1001['Label_List'] = re_1001['Label'].apply(string_to_list)\n","\n","# re_1001 데이터에 대한 리스트 형태의 레이블을 one-hot encoding으로 변환\n","re_1001['OneHot_Labels'] = re_1001['Label_List'].apply(lambda x: labels_to_onehot(x, label_to_num))\n","\n","# re_1000 데이터 프레임의 일부를 출력하여 확인\n","print(re_1000[['Review', 'Label_List', 'OneHot_Labels']].head())\n"],"metadata":{"id":"7NvKJehbihoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I97xAgWk69Pn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["re_1000[['Review', 'Label_List', 'OneHot_Labels']]"],"metadata":{"id":"8ZjekiwJii8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["re_1001[['Review', 'Label_List', 'OneHot_Labels']]"],"metadata":{"id":"wrN0SOC08I11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6qBwFXgBAFdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from transformers import AutoTokenizer\n","\n","# 모델 이름 및 토크나이저 정의\n","model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n","\n","# 주어진 데이터프레임에서 텍스트와 라벨을 인코딩하는 함수\n","def process_data(df, tokenizer):\n","    texts = df[\"Review\"].tolist()\n","    labels_encoded = np.array(df[\"OneHot_Labels\"].tolist())\n","\n","    # 텍스트 인코딩\n","    encodings = tokenizer(texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n","    return encodings, labels_encoded\n","\n","# 각 데이터셋에 대한 처리\n","train_encodings, train_labels_encoded = process_data(re_1000, tokenizer)\n","val_encodings, val_labels_encoded = process_data(re_1001, tokenizer)\n"],"metadata":{"id":"1pGtjpcQktpR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 첫 5개의 훈련 데이터 및 라벨 출력\n","for i in range(5):\n","    print(\"Review:\", re_1000[\"Review\"].iloc[i])\n","    print(\"Encoded:\", train_encodings['input_ids'][i])\n","    print(\"Label:\", train_labels_encoded[i])\n","    print(\"-\" * 50)\n","\n","# 첫 5개의 검증 데이터 및 라벨 출력\n","for i in range(5):\n","    print(\"Review:\", re_1001[\"Review\"].iloc[i])\n","    print(\"Encoded:\", val_encodings['input_ids'][i])\n","    print(\"Label:\", val_labels_encoded[i])\n","    print(\"-\" * 50)\n"],"metadata":{"id":"GSebjiAiCpjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from torch.utils.data import Dataset, DataLoader\n","\n","# class CustomDataset(Dataset):\n","#     def __init__(self, encodings, labels):\n","#         self.encodings = encodings\n","#         self.labels = labels\n","\n","#     def __getitem__(self, idx):\n","#         # item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","#         item = {key: val[idx].clone().detach().requires_grad_(True) for key, val in self.encodings.items()}\n","#         item['labels'] = torch.tensor(self.labels[idx])\n","\n","#         return item\n","\n","#     def __len__(self):\n","#         return len(self.labels)\n","\n","# # 데이터를 데이터셋으로 변환\n","# train_dataset = CustomDataset(train_encodings, train_labels_encoded)\n","# val_dataset = CustomDataset(val_encodings, val_labels_encoded)"],"metadata":{"id":"YXU4kOoxpGnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float).to('cuda')  # dtype을 명시적으로 설정\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# 데이터를 데이터셋으로 변환\n","train_dataset = CustomDataset(train_encodings, train_labels_encoded)\n","val_dataset = CustomDataset(val_encodings, val_labels_encoded)"],"metadata":{"id":"ddAyzdXXbI15"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# dataloader 생성"],"metadata":{"id":"VDYjVl9AFnC4"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","# DataLoader 설정\n","batch_size = 16  # 이 값은 메모리 및 학습 설정에 따라 조정해야 할 수 있습니다.\n","\n","train_dataset = CustomDataset(train_encodings, train_labels_encoded)\n","val_dataset = CustomDataset(val_encodings, val_labels_encoded)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","from transformers import AutoModelForSequenceClassification\n","from torch.optim import AdamW\n","from torch.nn import BCEWithLogitsLoss\n","\n","# 모델, 손실 함수, 옵티마이저 초기화\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True).to('cuda')\n","loss_fn = BCEWithLogitsLoss().to('cuda')\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n"],"metadata":{"id":"UKekzjrjFmT4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","import time\n","\n","epochs = 5\n","total_steps = len(train_loader) * epochs\n","model.train()\n","\n","for epoch in range(epochs):\n","    total_loss = 0\n","    epoch_start_time = time.time()  # 에폭 시작 시간 저장\n","\n","    # tqdm을 사용하여 학습의 진행 상황을 보여줌\n","    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n","\n","        # 배치 데이터를 CUDA에 할당\n","        inputs = batch['input_ids'].to('cuda')\n","        attention_mask = batch['attention_mask'].to('cuda')\n","        labels = batch['labels'].to('cuda')\n","\n","        # 예측 및 손실 계산\n","        outputs = model(inputs, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        loss = loss_fn(logits, labels.float())\n","\n","        # 역전파\n","        loss.backward()\n","\n","        # 가중치 업데이트\n","        optimizer.step()\n","\n","        # 그래디언트 초기화\n","        optimizer.zero_grad()\n","\n","        total_loss += loss.item()\n","\n","    avg_train_loss = total_loss / len(train_loader)\n","    epoch_time_elapsed = time.time() - epoch_start_time  # 에폭 경과 시간 계산\n","\n","    # 학습 로스와 에폭 경과 시간 출력\n","    print(f\"  평균 학습 loss: {avg_train_loss:.4f}\")\n","    print(f\"  에폭 토크 학습: {epoch_time_elapsed:.2f}s\")\n","\n","    model.save_pretrained(f\"{DATA_PATH}42000_5라벨_{epoch+1}\")\n","    tokenizer.save_pretrained(f\"{DATA_PATH}42000_5라벨_{epoch+1}\")\n","    print(f\"  에폭 저장 {epoch+1}\")\n","\n","print(\"완료\")\n"],"metadata":{"id":"1-_odX0fqqoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_zeroshot = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/프로젝트/final project/data/42000_5라벨_5\")\n"],"metadata":{"id":"mXqdDTIAhxQu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)\n","print(model.config)\n"],"metadata":{"id":"KXOX04ncM2rg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_zeroshot = model_zeroshot.to('cuda')\n","\n","model_zeroshot.eval()  # 모델을 평가 모드로 설정\n","\n","total_loss = 0\n","correct_predictions = 0\n","total_predictions = 0\n","\n","for batch in val_loader:\n","    with torch.no_grad():  # 기울기 계산을 하지 않음\n","        inputs = batch['input_ids'].to('cuda')\n","        attention_mask = batch['attention_mask'].to('cuda')\n","        labels = batch['labels'].to('cuda')\n","\n","        outputs = model_zeroshot(inputs, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        loss = loss_fn(logits, labels.float())\n","        total_loss += loss.item()\n","\n","        # 로지스틱 회귀 결과를 확률로 변환\n","        probs = torch.sigmoid(logits)\n","        # 확률을 라벨 (0 or 1)로 변환\n","        preds = (probs > 0.5).long()\n","\n","        correct_predictions += (preds == labels).sum().item()\n","        total_predictions += labels.numel()\n","\n","avg_val_loss = total_loss / len(val_loader)\n","accuracy = correct_predictions / total_predictions\n","\n","print(f\"Validation Loss: {avg_val_loss:.4f}\")\n","print(f\"Validation Accuracy: {accuracy:.4f}\")\n"],"metadata":{"id":"1WSn9lVzM3Tb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset\n","\n","# 데이터 추출\n","result_re1001 = result_df[\"Review\"][40000:42000].tolist()\n","\n","# 1. 데이터 전처리\n","inputs = tokenizer(result_re1001, truncation=True, padding=True, return_tensors=\"pt\")\n","\n","# TensorDataset 및 DataLoader 구성\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","data_loader = DataLoader(dataset, batch_size=16, shuffle=False)  # 배치 크기는 메모리에 따라 조정할 수 있습니다.\n","\n","# 2. 모델 예측\n","all_preds = []\n","with torch.no_grad():\n","    for batch in data_loader:\n","        input_ids, attention_mask = (item.to('cuda') for item in batch)\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        probs = torch.sigmoid(logits)\n","        preds = (probs > 0.5).long()  # 확률을 라벨 (0 or 1)로 변환\n","        all_preds.extend(preds.cpu().tolist())\n","\n","print(all_preds)\n"],"metadata":{"id":"SxT35MJqM8uZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# 레이블을 숫자로 변환하는 딕셔너리\n","label_to_num = {0: '맛', 1: '양', 2: '가격', 3: '배달', 4: '서비스'}\n","\n","# 모델 및 토크나이저 불러오기\n","# model = AutoModelForSequenceClassification.from_pretrained(\"rere_30000\").to('cuda')\n","tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\", use_fast=False)\n","\n","\n","# 데이터 추출\n","result_re30000 = result_df[\"Review\"][40000:42000].tolist()\n","\n","\n","\n","# 1. 데이터 전처리\n","inputs = tokenizer(result_re1001, truncation=True, padding=True, return_tensors=\"pt\")\n","\n","# TensorDataset 및 DataLoader 구성\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n","\n","# 2. 모델 예측\n","all_preds = []\n","with torch.no_grad():\n","    for batch in data_loader:\n","        input_ids, attention_mask = (item.to('cuda') for item in batch)\n","        outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        probs = torch.sigmoid(logits)\n","        preds = (probs > 0.5).long()  # 확률을 라벨 (0 or 1)로 변환\n","        all_preds.extend(preds.cpu().tolist())\n","\n","# 예측된 원-핫 인코딩된 라벨을 텍스트 라벨로 변환하는 함수\n","def one_hot_to_labels(one_hot_labels, label_to_num):\n","    labels_list = []\n","    for one_hot in one_hot_labels:\n","        labels = [label_to_num[i] for i, value in enumerate(one_hot) if value == 1]\n","        labels_list.append(labels)\n","    return labels_list\n","\n","# 예측된 원-핫 인코딩된 라벨을 텍스트 라벨로 변환\n","predicted_label_list = one_hot_to_labels(all_preds, label_to_num)\n","\n","# re_1001 데이터프레임에 예측된 라벨을 추가\n","result_df[\"Predicted_Labels\"] = [\"\"] * 40000 + predicted_label_list + [\"\"] * (len(result_df) - 42000)\n","\n","# 결과 출력\n","print(result_df[['Review', 'Predicted_Labels']].iloc[40000:42000])\n","result_df.to_csv(DATA_PATH + \"42000_zeroshot_fine.csv\", index=False)"],"metadata":{"id":"LQ8OhEEWNR6N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df[40000:42000]"],"metadata":{"id":"fFN8JqMxNuVF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y9iWmG6JNzWR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reviews_to_predict = [\n","    '맛은 있는데 양은 적어요',\n","    '가성비가 별로 안좋아요',\n","    '배 터질것 같아요',\n","    '이렇게 늦을 거면 안 시켜 먹었죠',\n","    '가격에 비해 양이 좀 적어요',\n","    '맛있는데 너무 늦게 왔어요',\n","    '맛에 비해 너무 비싸요',\n","    '다시는 안 시킬 것 같아요',\n","    '또 시켜먹을게요',\n","    '주문하고 30분 내로 왔어요',\n","    '혜자스럽네요',\n","    '창렬스럽네요',\n","    '이물질이 나왔어요',\n","    '국밥 국물이 끝내줘요',\n","    '치킨은 매번 여기서 시켜먹어요',\n","\n","\n","]\n"],"metadata":{"id":"uSkzxk0XxgML"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 제로샷 파이프라인 사용(fine-tuning모델)"],"metadata":{"id":"tIbOiN6d18Ga"}},{"cell_type":"code","source":["#model_zeroshot\n","\n","# 제로샷 분류 파이프라인 초기화\n","classifier = pipeline(\"zero-shot-classification\", model=model_zeroshot, tokenizer=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\", device=0)  # GPU 사용 설정\n","\n","# 분류를 위한 레이블 목록\n","candidate_labels = ['맛', '양', '가격', '배달', '서비스']\n","\n","# 전체 리뷰에 대해 제로샷 분류 수행\n","labels_collected = []\n","scores_collected = []\n","\n","for review in tqdm(reviews_to_predict):  # tqdm을 사용해 진행 상태 표시\n","    output = classifier(review, candidate_labels, multi_label=True)\n","    labels = [label for label, score in zip(output['labels'], output['scores']) if score > 0.5]\n","    scores = [round(score, 2) for score in output['scores']]\n","\n","    labels_collected.append(', '.join(labels))\n","    scores_collected.append(', '.join([f\"{label}: {round(score, 2)}\" for label, score in zip(output['labels'], output['scores'])]))\n","\n","# 결과를 데이터프레임으로 변환\n","lal = pd.DataFrame({\n","    'Review': reviews_to_predict,\n","    'Predicted_Labels': labels_collected,\n","    'Label_Scores': scores_collected\n","})\n","\n","# 결과 출력\n","lal"],"metadata":{"id":"qz0qvlAWx_iI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 제로샷 fine-tuning 결과"],"metadata":{"id":"C2BGL2xf11mB"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","\n","# zeroshot_model30000 = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/프로젝트/final project/data/zero_model_epoch_2\").to('cuda')\n","# model_zeroshot\n","candidate_labels = ['맛', '양', '가격', '배달', '서비스']\n","# 모델 및 토크나이저 불러오기\n","tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\", use_fast=False)\n","\n","# 데이터 전처리\n","inputs = tokenizer(reviews_to_predict, truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n","\n","# DataLoader 구성\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n","\n","labels_collected = []\n","scores_collected = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(data_loader):\n","        input_ids, attention_mask = (item.to('cuda') for item in batch)\n","        outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        probs = torch.sigmoid(logits).cpu().numpy()\n","\n","        for prob in probs:\n","            labels = [candidate_labels[idx] for idx, val in enumerate(prob) if val > 0.5]\n","            scores = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(prob)}\n","\n","            labels_collected.append(\", \".join(labels))\n","            scores_collected.append(\", \".join([f\"{k}: {v}\" for k, v in scores.items()]))\n","\n","# 결과를 데이터 프레임으로 저장\n","result_df = pd.DataFrame({\n","    'Review': reviews_to_predict,\n","    'Predicted_Labels': labels_collected,\n","    'Label_Scores': scores_collected\n","})\n","\n","result_df"],"metadata":{"id":"Xl9v-Whfkgex"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 제로샷 \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\" 모델 사용 결과"],"metadata":{"id":"wdV_LoCa3ikN"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import torch\n","from tqdm.auto import tqdm\n","import random\n","import os\n","\n","def reset_seeds(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# DATA_PATH = \"/content/drive/MyDrive/생성 AI 모델링/data/\"\n","DATA_PATH = \"data/\"\n","SEED = 42\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device\n"],"metadata":{"id":"05vFSVXMrcDq","executionInfo":{"status":"ok","timestamp":1695432981154,"user_tz":-540,"elapsed":316,"user":{"displayName":"","userId":""}},"outputId":"9214a8a0-632e-4122-8a3a-4095c2dcfe1f","colab":{"base_uri":"https://localhost:8080/","height":36}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["review = pd.read_csv('filtered_pos_train_2000_3000.csv')\n","review['review']\n","\n","review_list = review['review'].tolist()[:5]\n","review_list\n"],"metadata":{"id":"2PXWsyEtrnB_","executionInfo":{"status":"ok","timestamp":1695433588049,"user_tz":-540,"elapsed":422,"user":{"displayName":"","userId":""}},"outputId":"bb872346-93cc-4ae2-afc7-f8d2d4b162d7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['맛도 양도 모두 만족합니다 배달도 정확히 보내 주시고 아주 만족합니다.',\n"," '너무 맛있게 잘 먹었습니다!',\n"," '너무 배고파서 먹다가 찍었어요. 너무맛있어요',\n"," '두번째시켜요~ 이번엔 아이들이 잡채가 먹고싶대서 주문해봤는데 고기도 많이 들어가있고 넘 맛있어요~! 그리고 서비스 묵사발 맛이 진짜 예술입니다 담엔 추가로도 시키려고요! 잘 먹었습니다',\n"," '푸짐하고 너무 맛있어용~']"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n","from tqdm import tqdm\n","\n","# 모델과 토크나이저 초기화\n","model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# 제로샷 분류 파이프라인 초기화\n","classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)  # GPU 사용 설정\n","\n","# 분류를 위한 레이블 목록\n","candidate_labels = ['맛', '양', '가격', '배달', '서비스']\n","\n","# 전체 리뷰에 대해 제로샷 분류 수행\n","labels_collected = []\n","scores_collected = []"],"metadata":{"id":"hEJiPk_VsUWn","executionInfo":{"status":"ok","timestamp":1695433515487,"user_tz":-540,"elapsed":10591,"user":{"displayName":"","userId":""}},"outputId":"4a791e08-536d-473f-a33a-ecebf33eabd7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["\n","review = pd.read_csv('filtered_pos_train_2000_3000.csv')\n","review['review']\n","\n","review_list = review['review'].tolist()[:5]\n","review_list\n","\n","\n","from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n","from tqdm import tqdm\n","\n","# 모델과 토크나이저 초기화\n","model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# 제로샷 분류 파이프라인 초기화\n","classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)  # GPU 사용 설정\n","\n","# 분류를 위한 레이블 목록\n","candidate_labels = ['맛', '양', '가격', '배달', '서비스']\n","\n","# 전체 리뷰에 대해 제로샷 분류 수행\n","labels_collected = []\n","scores_collected = []\n","new_labels_collected = []\n","new_scores_collected = []"],"metadata":{"id":"rBqg1Lhgyz6w","executionInfo":{"status":"ok","timestamp":1695434897973,"user_tz":-540,"elapsed":11126,"user":{"displayName":"","userId":""}},"outputId":"c7d4b521-0e14-4110-9351-cbd18a01366a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["\n","\n","for review_text in tqdm(review_list):  # 리스트를 바로 순회\n","    output = classifier(review_text, candidate_labels, multi_label=True)\n","    labels = [label for label, score in zip(output['labels'], output['scores']) if score > 0.5]\n","    scores = [round(score, 2) for score in output['scores']]\n","\n","\n","    # # new_labels와 new_scores 초기화\n","    # new_labels = set()\n","    # new_scores = {'quality': 0.0, 'quantity': 0.0, 'service': 0.0}\n","\n","    # # 레이블과 점수를 동시에 처리\n","    # for label, score in zip(labels, scores):\n","    #     if '맛' in label:\n","    #         new_labels.add('quality')\n","    #         new_scores['quality'] += score\n","    #     if '양' in label:\n","    #         new_labels.add('quantity')\n","    #         new_scores['quantity'] += score\n","    #     if '배달' in label or '서비스' in label or '가격' in label:\n","    #         new_labels.add('service')\n","    #         new_scores['service'] += score\n","\n","    # # 스코어 평균 계산\n","    # for 'service' in new_scores:\n","    #     new_scores[key] /= len(new_labels)\n","\n","    # # 중복 제거\n","    # new_labels = list(new_labels)\n","\n","    # labels_collected.append(', '.join(labels))\n","    # # scores_collected.append(', '.join([f\"{label}: {round(score, 2)}\" for label, score in zip(output['labels'], output['scores'])]))\n","    # new_labels_collected.append(', '.join(new_labels))\n","    # # new_scores_collected.append(', '.join([f\"{new_labels}: {round(score, 2)}\" for label, score in zip(output['new_labels'], output['new_scores'])]))\n","\n","    # new_labels와 new_scores 초기화\n","    new_labels = set()\n","    new_scores = {'quality': 0.0, 'quantity': 0.0, 'service': 0.0}\n","\n","    # 레이블과 점수를 동시에 처리\n","    for label, score in zip(labels, scores):\n","        if '맛' in label:\n","            new_labels.add('quality')\n","            new_scores['quality'] += score\n","        if '양' in label:\n","            new_labels.add('quantity')\n","            new_scores['quantity'] += score\n","        if '배달' in label or '서비스' in label or '가격' in label:\n","            new_labels.add('service')\n","            new_scores['service'] += score\n","\n","    # 스코어 평균 계산\n","    for key in new_scores:\n","        if key == 'service':\n","            new_scores[key] /= len(new_labels)\n","\n","    # 중복 제거\n","    new_labels = list(new_labels)\n","\n","    labels_collected.append(', '.join(labels))\n","\n","    new_labels_collected.append(', '.join(new_labels))\n","\n","    scores_collected.append(', '.join([f\"{label}: {round(score, 2)}\" for label, score in zip(output['labels'], output['scores'])]))\n","\n","    new_scores_collected.append(', '.join(new_scores))\n","\n","\n","\n","# 결과를 데이터프레임으로 변환\n","result_df = pd.DataFrame({\n","    'Review': review_list,\n","    'Predicted_Labels': labels_collected[:len(review_list)],\n","    'Label_Scores': scores_collected[:len(review_list)],\n","    'new_labels' : new_labels_collected[:len(review_list)],\n","    'new_scores' : new_scores_collected[:len(review_list)]\n","})\n","\n","\n","# result_df['Predicted_Labels'] = result_df['Predicted_Labels'].str.replace('맛', 'quality')\n","\n","# # '양'을 'quantity'로 변환\n","# result_df['Predicted_Labels'] = result_df['Predicted_Labels'].str.replace('양', 'quantity')\n","\n","# result_df['Predicted_Labels'] = result_df.apply(lambda row: 'service' if row['Predicted_Labels'] in ['가격', '배달', '서비스'] else row['Predicted_Labels'], axis=1)\n","\n","# result_df['Predicted_Labels']  = unique_predicted_labels = set(result_df['Predicted_Labels'])\n","\n","\n","\n","result_df\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"Xz6Ba6Uz2pMJ","outputId":"03b3dd1e-f337-4ecb-effa-576266d957ca","executionInfo":{"status":"ok","timestamp":1695435743002,"user_tz":-540,"elapsed":22224,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:21<00:00,  4.33s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["                                              Review   Predicted_Labels  \\\n","0            맛도 양도 모두 만족합니다 배달도 정확히 보내 주시고 아주 만족합니다.      배달, 서비스, 맛, 양   \n","1                                    너무 맛있게 잘 먹었습니다!      배달, 서비스, 맛, 양   \n","2                           너무 배고파서 먹다가 찍었어요. 너무맛있어요                  맛   \n","3  두번째시켜요~ 이번엔 아이들이 잡채가 먹고싶대서 주문해봤는데 고기도 많이 들어가있고...             맛, 서비스   \n","4                                      푸짐하고 너무 맛있어용~  서비스, 맛, 배달, 가격, 양   \n","\n","                                     Label_Scores                  new_labels  \\\n","0     배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0  service, quality, quantity   \n","1     배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0  service, quality, quantity   \n","2     배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0                     quality   \n","3   맛: 0.99, 서비스: 0.39, 양: 0.03, 배달: 0.0, 가격: 0.0            service, quality   \n","4  맛: 0.99, 서비스: 0.75, 배달: 0.38, 양: 0.29, 가격: 0.2  service, quality, quantity   \n","\n","                   new_scores  \n","0  quality, quantity, service  \n","1  quality, quantity, service  \n","2  quality, quantity, service  \n","3  quality, quantity, service  \n","4  quality, quantity, service  "],"text/html":["\n","  <div id=\"df-a0f4e262-2045-4907-ae69-5bd2705eca76\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Predicted_Labels</th>\n","      <th>Label_Scores</th>\n","      <th>new_labels</th>\n","      <th>new_scores</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>맛도 양도 모두 만족합니다 배달도 정확히 보내 주시고 아주 만족합니다.</td>\n","      <td>배달, 서비스, 맛, 양</td>\n","      <td>배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0</td>\n","      <td>service, quality, quantity</td>\n","      <td>quality, quantity, service</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>너무 맛있게 잘 먹었습니다!</td>\n","      <td>배달, 서비스, 맛, 양</td>\n","      <td>배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0</td>\n","      <td>service, quality, quantity</td>\n","      <td>quality, quantity, service</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>너무 배고파서 먹다가 찍었어요. 너무맛있어요</td>\n","      <td>맛</td>\n","      <td>배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0</td>\n","      <td>quality</td>\n","      <td>quality, quantity, service</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>두번째시켜요~ 이번엔 아이들이 잡채가 먹고싶대서 주문해봤는데 고기도 많이 들어가있고...</td>\n","      <td>맛, 서비스</td>\n","      <td>맛: 0.99, 서비스: 0.39, 양: 0.03, 배달: 0.0, 가격: 0.0</td>\n","      <td>service, quality</td>\n","      <td>quality, quantity, service</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>푸짐하고 너무 맛있어용~</td>\n","      <td>서비스, 맛, 배달, 가격, 양</td>\n","      <td>맛: 0.99, 서비스: 0.75, 배달: 0.38, 양: 0.29, 가격: 0.2</td>\n","      <td>service, quality, quantity</td>\n","      <td>quality, quantity, service</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0f4e262-2045-4907-ae69-5bd2705eca76')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a0f4e262-2045-4907-ae69-5bd2705eca76 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a0f4e262-2045-4907-ae69-5bd2705eca76');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-47f39beb-0ee7-4585-96c4-97c599774366\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47f39beb-0ee7-4585-96c4-97c599774366')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-47f39beb-0ee7-4585-96c4-97c599774366 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["import pandas as pd\n","from tqdm import tqdm\n","from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n","\n","# 모델과 토크나이저 초기화\n","model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# 제로샷 분류 파이프라인 초기화\n","classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)  # GPU 사용 설정\n","\n","# 분류를 위한 레이블 목록\n","candidate_labels = ['맛', '양', '가격', '배달', '서비스']\n","\n","# 결과를 저장할 리스트 초기화\n","labels_collected = []\n","scores_collected = []\n","new_labels_collected = []\n","new_scores_collected = []\n","\n","# 리뷰 데이터 (예: 리뷰 데이터가 들어있는 리스트 reviews)\n","reviews = review['review']\n","\n","# 각 리뷰에 대해 제로샷 분류 수행\n","for review_text in tqdm(reviews[:100]):  # 처음 10개 리뷰만 예시로 사용\n","    output = classifier(review_text, candidate_labels, multi_label=True)\n","    labels = [label for label, score in zip(output['labels'], output['scores']) if score > 0.4]\n","    scores = [round(score, 2) for score in output['scores']]\n","\n","    # new_labels와 new_scores 초기화\n","    new_labels = set()\n","    new_scores = {'음식': 0.0, '양': 0.0, '서비스': 0.0}\n","\n","    # 레이블과 점수를 동시에 처리\n","    for label, score in zip(labels, scores):\n","        if '맛' in label:\n","            new_labels.add('음식')\n","            new_scores['음식'] += score\n","        if '양' in label:\n","            new_labels.add('양')\n","            new_scores['양'] += score\n","        if '배달' in label or '서비스' in label or '가격' in label:\n","            new_labels.add('서비스')\n","            new_scores['서비스'] += score\n","\n","    # 스코어 평균 계산\n","    for key in new_scores:\n","        if key == '서비스':\n","            new_scores[key] /= len(new_labels)\n","\n","    # 중복 제거\n","    new_labels = list(new_labels)\n","\n","    labels_collected.append(', '.join(labels))\n","    new_labels_collected.append(', '.join(new_labels))\n","    scores_collected.append(', '.join([f\"{label}: {round(score, 2)}\" for label, score in zip(output['labels'], output['scores'])]))\n","    new_scores_collected.append(', '.join([f\"{key}: {round(value, 2)}\" for key, value in new_scores.items()]))\n","\n","# 결과를 데이터프레임으로 변환\n","result_df = pd.DataFrame({\n","    'Review': reviews[:100],  # 처음 10개 리뷰만 사용\n","    'Predicted_Labels': labels_collected[:100],  # 처음 10개 리뷰만 사용\n","    'Label_Scores': scores_collected[:100],  # 처음 10개 리뷰만 사용\n","    'New_Labels': new_labels_collected[:100],  # 처음 10개 리뷰만 사용\n","    'New_Scores': new_scores_collected[:100],  # 처음 10개 리뷰만 사용\n","})\n","\n","# 결과 출력\n","result_df\n","\n","# result_df[['Review','New_Labels','New_Scores']]\n"],"metadata":{"id":"5jRAtPsU2ep_","executionInfo":{"status":"ok","timestamp":1695438024834,"user_tz":-540,"elapsed":248860,"user":{"displayName":"","userId":""}},"outputId":"5fa5e017-e0db-48be-b281-1b8bce9a2f95","colab":{"base_uri":"https://localhost:8080/","height":671}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","100%|██████████| 100/100 [03:59<00:00,  2.40s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["                                               Review   Predicted_Labels  \\\n","0             맛도 양도 모두 만족합니다 배달도 정확히 보내 주시고 아주 만족합니다.      배달, 서비스, 맛, 양   \n","1                                     너무 맛있게 잘 먹었습니다!                  맛   \n","2                            너무 배고파서 먹다가 찍었어요. 너무맛있어요             맛, 서비스   \n","3   두번째시켜요~ 이번엔 아이들이 잡채가 먹고싶대서 주문해봤는데 고기도 많이 들어가있고...  서비스, 맛, 배달, 가격, 양   \n","4                                       푸짐하고 너무 맛있어용~                  맛   \n","..                                                ...                ...   \n","95  커피랑 주스는 원래 맛있고, 티라미수는 걍 같이 주문해 본 건데 오우 카카오닙스 뿌...             맛, 서비스   \n","96                                     무조건 사먹으셈 진짜 최고                  맛   \n","97                                또 주문했어요 여기 커피 최고에요          맛, 서비스, 배달   \n","98  생크림이랑 잼 겁나 맛이 풍부하고 느끼함 없는데다 무겁게 느껴지지도 않아요.특히 밀...      서비스, 맛, 배달, 양   \n","99  내가 방금 와플을 먹은 건지 천상을 맛본건지. 너무 감동이에요. 다 먹어버려서 사진...                  맛   \n","\n","                                       Label_Scores  New_Labels  \\\n","0       배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0  음식, 양, 서비스   \n","1     맛: 0.99, 서비스: 0.39, 양: 0.03, 배달: 0.0, 가격: 0.0          음식   \n","2    맛: 0.99, 서비스: 0.75, 배달: 0.38, 양: 0.29, 가격: 0.2     음식, 서비스   \n","3     서비스: 1.0, 맛: 1.0, 배달: 0.98, 가격: 0.86, 양: 0.82  음식, 양, 서비스   \n","4   맛: 0.99, 서비스: 0.22, 양: 0.17, 배달: 0.04, 가격: 0.01          음식   \n","..                                              ...         ...   \n","95  맛: 0.99, 서비스: 0.88, 배달: 0.07, 양: 0.01, 가격: 0.01     음식, 서비스   \n","96  맛: 0.96, 가격: 0.29, 서비스: 0.08, 양: 0.05, 배달: 0.01          음식   \n","97   맛: 1.0, 서비스: 0.99, 배달: 0.46, 가격: 0.21, 양: 0.03     음식, 서비스   \n","98     서비스: 1.0, 맛: 1.0, 배달: 0.89, 양: 0.8, 가격: 0.26  음식, 양, 서비스   \n","99     맛: 0.61, 서비스: 0.01, 가격: 0.0, 양: 0.0, 배달: 0.0          음식   \n","\n","                     New_Scores  \n","0   음식: 1.0, 양: 0.98, 서비스: 0.67  \n","1    음식: 0.99, 양: 0.0, 서비스: 0.0  \n","2   음식: 0.99, 양: 0.0, 서비스: 0.38  \n","3   음식: 1.0, 양: 0.82, 서비스: 0.95  \n","4    음식: 0.99, 양: 0.0, 서비스: 0.0  \n","..                          ...  \n","95  음식: 0.99, 양: 0.0, 서비스: 0.44  \n","96   음식: 0.96, 양: 0.0, 서비스: 0.0  \n","97   음식: 1.0, 양: 0.0, 서비스: 0.72  \n","98   음식: 1.0, 양: 0.8, 서비스: 0.63  \n","99   음식: 0.61, 양: 0.0, 서비스: 0.0  \n","\n","[100 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-5891feec-d899-4c9a-9c75-448af22881ef\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Predicted_Labels</th>\n","      <th>Label_Scores</th>\n","      <th>New_Labels</th>\n","      <th>New_Scores</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>맛도 양도 모두 만족합니다 배달도 정확히 보내 주시고 아주 만족합니다.</td>\n","      <td>배달, 서비스, 맛, 양</td>\n","      <td>배달: 1.0, 서비스: 1.0, 맛: 1.0, 양: 0.98, 가격: 0.0</td>\n","      <td>음식, 양, 서비스</td>\n","      <td>음식: 1.0, 양: 0.98, 서비스: 0.67</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>너무 맛있게 잘 먹었습니다!</td>\n","      <td>맛</td>\n","      <td>맛: 0.99, 서비스: 0.39, 양: 0.03, 배달: 0.0, 가격: 0.0</td>\n","      <td>음식</td>\n","      <td>음식: 0.99, 양: 0.0, 서비스: 0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>너무 배고파서 먹다가 찍었어요. 너무맛있어요</td>\n","      <td>맛, 서비스</td>\n","      <td>맛: 0.99, 서비스: 0.75, 배달: 0.38, 양: 0.29, 가격: 0.2</td>\n","      <td>음식, 서비스</td>\n","      <td>음식: 0.99, 양: 0.0, 서비스: 0.38</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>두번째시켜요~ 이번엔 아이들이 잡채가 먹고싶대서 주문해봤는데 고기도 많이 들어가있고...</td>\n","      <td>서비스, 맛, 배달, 가격, 양</td>\n","      <td>서비스: 1.0, 맛: 1.0, 배달: 0.98, 가격: 0.86, 양: 0.82</td>\n","      <td>음식, 양, 서비스</td>\n","      <td>음식: 1.0, 양: 0.82, 서비스: 0.95</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>푸짐하고 너무 맛있어용~</td>\n","      <td>맛</td>\n","      <td>맛: 0.99, 서비스: 0.22, 양: 0.17, 배달: 0.04, 가격: 0.01</td>\n","      <td>음식</td>\n","      <td>음식: 0.99, 양: 0.0, 서비스: 0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>커피랑 주스는 원래 맛있고, 티라미수는 걍 같이 주문해 본 건데 오우 카카오닙스 뿌...</td>\n","      <td>맛, 서비스</td>\n","      <td>맛: 0.99, 서비스: 0.88, 배달: 0.07, 양: 0.01, 가격: 0.01</td>\n","      <td>음식, 서비스</td>\n","      <td>음식: 0.99, 양: 0.0, 서비스: 0.44</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>무조건 사먹으셈 진짜 최고</td>\n","      <td>맛</td>\n","      <td>맛: 0.96, 가격: 0.29, 서비스: 0.08, 양: 0.05, 배달: 0.01</td>\n","      <td>음식</td>\n","      <td>음식: 0.96, 양: 0.0, 서비스: 0.0</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>또 주문했어요 여기 커피 최고에요</td>\n","      <td>맛, 서비스, 배달</td>\n","      <td>맛: 1.0, 서비스: 0.99, 배달: 0.46, 가격: 0.21, 양: 0.03</td>\n","      <td>음식, 서비스</td>\n","      <td>음식: 1.0, 양: 0.0, 서비스: 0.72</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>생크림이랑 잼 겁나 맛이 풍부하고 느끼함 없는데다 무겁게 느껴지지도 않아요.특히 밀...</td>\n","      <td>서비스, 맛, 배달, 양</td>\n","      <td>서비스: 1.0, 맛: 1.0, 배달: 0.89, 양: 0.8, 가격: 0.26</td>\n","      <td>음식, 양, 서비스</td>\n","      <td>음식: 1.0, 양: 0.8, 서비스: 0.63</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>내가 방금 와플을 먹은 건지 천상을 맛본건지. 너무 감동이에요. 다 먹어버려서 사진...</td>\n","      <td>맛</td>\n","      <td>맛: 0.61, 서비스: 0.01, 가격: 0.0, 양: 0.0, 배달: 0.0</td>\n","      <td>음식</td>\n","      <td>음식: 0.61, 양: 0.0, 서비스: 0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5891feec-d899-4c9a-9c75-448af22881ef')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5891feec-d899-4c9a-9c75-448af22881ef button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5891feec-d899-4c9a-9c75-448af22881ef');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-823db335-78f3-486a-abea-2fd3cf0b1050\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-823db335-78f3-486a-abea-2fd3cf0b1050')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-823db335-78f3-486a-abea-2fd3cf0b1050 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":[],"metadata":{"id":"sRaL-MfJ4SrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","# from tqdm import tqdm\n","# from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n","\n","# # 모델과 토크나이저 초기화\n","# model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","# model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n","# tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# # 제로샷 분류 파이프라인 초기화\n","# classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer)  # GPU 사용 설정\n","\n","# # 분류를 위한 레이블 목록\n","# candidate_labels = ['맛', '양', '가격', '배달', '서비스']\n","\n","# # 결과를 저장할 리스트 초기화\n","# labels_collected = []\n","# scores_collected = []\n","\n","# # 리뷰 데이터 (예: 리뷰 데이터가 들어있는 리스트 reviews)\n","# reviews = review['review']\n","\n","# 각 리뷰에 대해 제로샷 분류 수행\n","for review in tqdm(review_list):  # 처음 10개 리뷰만 예시로 사용\n","    output = classifier(review, candidate_labels, multi_label=True)\n","    labels = [label for label, score in zip(output['labels'], output['scores']) if score > 0.5]\n","    scores = [round(score, 2) for score in output['scores']]\n","\n","    labels_collected.append(', '.join(labels))\n","    scores_collected.append(scores)  # 점수 리스트를 그대로 저장\n","\n","# 결과를 데이터프레임으로 변환\n","result_df = pd.DataFrame({\n","    'Review': review_list,  # 처음 10개 리뷰만 사용\n","    'Predicted_Labels': labels_collected,\n","    'Label_Scores': scores_collected,\n","})\n","\n","# '맛'을 'quality'로 변환\n","result_df['Predicted_Labels'] = result_df['Predicted_Labels'].str.replace('맛', 'quality')\n","\n","# '양'을 'quantity'로 변환\n","result_df['Predicted_Labels'] = result_df['Predicted_Labels'].str.replace('양', 'quantity')\n","\n","result_df['Predicted_Labels'] = result_df.apply(lambda row: 'service' if row['Predicted_Labels'] in ['가격', '배달', '서비스'] else row['Predicted_Labels'], axis=1)\n","\n","result_df['Predicted_Labels']  = unique_predicted_labels = set(result_df['Predicted_Labels'])\n","\n","# # 'quality' 점수의 총합 계산\n","# result_df['Quality_Score_Total'] = result_df.apply(lambda row: sum(row['Label_Scores']) if row['Predicted_Labels'] == 'quality' else 0, axis=1)\n","\n","# # 'quality' 점수의 총합의 평균 계산\n","# quality_scores = result_df[result_df['Predicted_Labels'] == 'quality']['Quality_Score_Total']\n","# average_quality_score = quality_scores.mean()\n","\n","# # 결과 출력\n","# result_df\n","# print(f'평균 Quality 점수: {average_quality_score}')\n"],"metadata":{"id":"nGvjnKLbs2ta","executionInfo":{"status":"error","timestamp":1695433751383,"user_tz":-540,"elapsed":19314,"user":{"displayName":"","userId":""}},"outputId":"dc7464db-9f1a-4f52-f708-28e627f1744c","colab":{"base_uri":"https://localhost:8080/","height":421}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:18<00:00,  3.80s/it]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-5ed241339d7d>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# 결과를 데이터프레임으로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m result_df = pd.DataFrame({\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;34m'Review'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreview_list\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 처음 10개 리뷰만 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m'Predicted_Labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_collected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"]}]},{"cell_type":"markdown","source":["# 산술평균 예측(0.5이상 추가)"],"metadata":{"id":"rx9RSsQrQnSs"}},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","from tqdm import tqdm\n","import pandas as pd\n","\n","# 첫 번째 모델\n","# zeroshot_model30000 = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/프로젝트/final project/data/zero_model_epoch_2\").to('cuda')\n","# model_zeroshot\n","\n","\n","# 두 번째 모델\n","model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","model = AutoModelForSequenceClassification.from_pretrained(model_name).to('cuda')\n","classifier = pipeline(\"zero-shot-classification\", model=model, tokenizer=tokenizer, device=0)\n","\n","# 공통 토크나이저\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n","\n","# 데이터 전처리\n","inputs = tokenizer(reviews_to_predict, truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n","dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n","data_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n","\n","# 모델 1 예측\n","scores_from_model1 = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(data_loader):\n","        input_ids, attention_mask = (item.to('cuda') for item in batch)\n","        outputs = model_zeroshot(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        probs = torch.sigmoid(logits).cpu().numpy()\n","\n","        for prob in probs:\n","            scores = {candidate_labels[idx]: f\"{val:.2f}\" for idx, val in enumerate(prob)}\n","            scores_from_model1.append(scores)\n","\n","# 모델 2 예측\n","scores_from_model2 = []\n","\n","for review in tqdm(reviews_to_predict):\n","    output = classifier(review, candidate_labels, multi_label=True)\n","    scores = {label: round(score, 2) for label, score in zip(output['labels'], output['scores'])}\n","    scores_from_model2.append(scores)\n","\n","averaged_scores_list = []\n","predicted_labels_list = []\n","\n","\n","\n","\n","for score1, score2 in zip(scores_from_model1, scores_from_model2):\n","    # 산술평균 저장\n","    averaged_scores = {}\n","    # 산술평균 점수가 0.5 이상인 레이블을 저장할 리스트\n","    predicted_labels = []\n","\n","    for label in score1.keys():\n","        # 두 모델 점수 산술평균\n","        averaged_score = (float(score1[label]) + float(score2[label])) / 2\n","        # 산술평균 점수 소수점 둘째 자리 까지\n","        averaged_scores[label] = \"{:.2f}\".format(averaged_score)\n","\n","        # 산술평균 점수가 0.5 이상이면 해당 레이블 추가\n","        if averaged_score > 0.5:\n","            predicted_labels.append(label)\n","\n","    # 각 리뷰에 대한 산술평균 점수를 averaged_scores에 추가.\n","    averaged_scores_list.append(\", \".join([f\"{k}: {v}\" for k, v in averaged_scores.items()]))\n","    # 각 리뷰에 대한 산술평균 점수가 0.5 이상인 레이블을 predicted_labels에 추가\n","    predicted_labels_list.append(\", \".join(predicted_labels))\n","\n","result_df = pd.DataFrame({\n","    'Review': reviews_to_predict,\n","    'Predicted_Labels': predicted_labels_list,\n","    'Averaged_Label_Scores': averaged_scores_list\n","})\n","\n","result_df\n"],"metadata":{"id":"kF0AM29A_LdJ","colab":{"base_uri":"https://localhost:8080/","height":421},"outputId":"82617f4e-069e-4090-9c81-fc29c14bbd91","executionInfo":{"status":"error","timestamp":1695432896461,"user_tz":-540,"elapsed":19746,"user":{"displayName":"","userId":""}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-d039340675fe>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 두 번째 모델\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zero-shot-classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2063\u001b[0m             )\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}]}]}